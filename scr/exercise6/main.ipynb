{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T09:45:44.639231Z",
     "start_time": "2025-06-30T09:45:44.599037Z"
    }
   },
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "dis_db_password = os.getenv(\"REMOTE_POSTGRES_DIS_PASSWORD\")\n",
    "\n",
    "conn_params = {\n",
    "    'host': 'vsisdb.informatik.uni-hamburg.de',\n",
    "    'dbname': 'dis-2025',\n",
    "    'user': 'vsisp42',\n",
    "    'password': dis_db_password\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T09:47:09.175509Z",
     "start_time": "2025-06-30T09:47:08.858797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_existing_tables():\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                SELECT table_name\n",
    "                FROM information_schema.tables\n",
    "                WHERE table_schema = %s\n",
    "                ORDER BY table_name;\n",
    "                \"\"\",\n",
    "                (conn_params[\"user\"],),\n",
    "            )\n",
    "            tables = cur.fetchall()\n",
    "\n",
    "            for table in tables:\n",
    "                print(\"-\", table[0])\n",
    "show_existing_tables()"
   ],
   "id": "c91b3afd2f46f9df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- article\n",
      "- city\n",
      "- country\n",
      "- productcategory\n",
      "- productfamily\n",
      "- productgroup\n",
      "- region\n",
      "- shop\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:36:45.497147Z",
     "start_time": "2025-06-30T06:36:45.445312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/sales.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read(10000))\n",
    "\n",
    "print(result)"
   ],
   "id": "45f5542699c8ba72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T06:44:51.019797Z",
     "start_time": "2025-06-30T06:44:50.978232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bad_lines = []\n",
    "with open('resources/sales.csv', encoding='ISO-8859-1') as f:\n",
    "    for i, line in enumerate(f, start=1):\n",
    "        if line.count(';') != 4:  # 4 Semikolons = 5 Spalten\n",
    "            bad_lines.append((i, line.strip()))\n",
    "\n",
    "for i, l in bad_lines:\n",
    "    print(f\"Fehler in Zeile {i}: {l}\")"
   ],
   "id": "d36cfb2d813d6333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler in Zeile 35906: 06.04.2019;12.03.2019;Superstore Dresden;AEG Öko Lavatherm 59850 Sensidry;3;2997,00\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T10:06:58.137811Z",
     "start_time": "2025-06-30T10:06:58.046573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_csv_data():\n",
    "    return pd.read_csv(\n",
    "        'resources/sales.csv',\n",
    "        encoding='ISO-8859-1',\n",
    "        sep=';',\n",
    "        decimal=',',\n",
    "        on_bad_lines='skip'\n",
    "    )\n",
    "\n",
    "df = load_csv_data()\n",
    "print(df.head())\n"
   ],
   "id": "6f044104fb29fba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date               Shop                           Article  Sold  \\\n",
      "0  01.01.2019  Superstore Berlin  AEG Öko Lavatherm 59850 Sensidry    25   \n",
      "1  01.01.2019  Superstore Berlin     AEG Öko-Lavamat Öko Plus 1400    25   \n",
      "2  01.01.2019  Superstore Berlin              Bauknecht TK Care 6B    13   \n",
      "3  01.01.2019  Superstore Berlin      Bauknecht WA Sensitive 36 DI     2   \n",
      "4  01.01.2019  Superstore Berlin                       BenQ DE350P    31   \n",
      "\n",
      "    Revenue  \n",
      "0  24975.00  \n",
      "1  14975.00  \n",
      "2   3639.74  \n",
      "3    699.80  \n",
      "4   8369.69  \n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T09:49:24.417286Z",
     "start_time": "2025-06-30T09:49:24.264148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_star_schema_tables(conn):\n",
    "    with conn.cursor() as cur:\n",
    "        # Produktdimension\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS dim_product (\n",
    "                product_id SERIAL PRIMARY KEY,\n",
    "                article_id INT,\n",
    "                article_name VARCHAR(255),\n",
    "                product_group_id INT,\n",
    "                product_group_name VARCHAR(255),\n",
    "                product_family_id INT,\n",
    "                product_family_name VARCHAR(255),\n",
    "                product_category_id INT,\n",
    "                product_category_name VARCHAR(255)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "        # Geodimension\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS dim_geo (\n",
    "                geo_id SERIAL PRIMARY KEY,\n",
    "                shop_id INT,\n",
    "                shop_name VARCHAR(255),\n",
    "                city_id INT,\n",
    "                city_name VARCHAR(255),\n",
    "                region_id INT,\n",
    "                region_name VARCHAR(255),\n",
    "                country_id INT,\n",
    "                country_name VARCHAR(255)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        # Zeitdimension\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS dim_time (\n",
    "                time_id SERIAL PRIMARY KEY,\n",
    "                date DATE,\n",
    "                day INT,\n",
    "                month INT,\n",
    "                quarter INT,\n",
    "                year INT\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        # Faktentabelle\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS fact_sales (\n",
    "                sales_id SERIAL PRIMARY KEY,\n",
    "                time_id INT,\n",
    "                geo_id INT,\n",
    "                product_id INT,\n",
    "                quantity INT,\n",
    "                revenue NUMERIC,\n",
    "\n",
    "                CONSTRAINT fk_time FOREIGN KEY (time_id) REFERENCES dim_time(time_id),\n",
    "                CONSTRAINT fk_geo FOREIGN KEY (geo_id) REFERENCES dim_geo(geo_id),\n",
    "                CONSTRAINT fk_product FOREIGN KEY (product_id) REFERENCES dim_product(product_id)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Star-Schema-Tabellen erfolgreich erstellt.\")\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    create_star_schema_tables(conn)"
   ],
   "id": "b337d55f28f87295",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star-Schema-Tabellen erfolgreich erstellt.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ba1c020402040656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T10:01:16.792740Z",
     "start_time": "2025-06-30T10:01:16.694899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def populate_dim_product(conn):\n",
    "    with conn.cursor() as cur:\n",
    "         cur.execute(\"\"\"\n",
    "            INSERT INTO dim_product (\n",
    "                article_id,\n",
    "                article_name,\n",
    "                product_group_id,\n",
    "                product_group_name,\n",
    "                product_family_id,\n",
    "                product_family_name,\n",
    "                product_category_id,\n",
    "                product_category_name\n",
    "            )\n",
    "            SELECT\n",
    "                a.ArticleID,\n",
    "                a.Name,\n",
    "                pg.ProductGroupID,\n",
    "                pg.Name,\n",
    "                pf.ProductFamilyID,\n",
    "                pf.Name,\n",
    "                pc.ProductCategoryID,\n",
    "                pc.Name\n",
    "            FROM Article a\n",
    "                INNER JOIN ProductGroup pg ON pg.productgroupid = a.productgroupid\n",
    "                INNER JOIN vsisp42.productfamily pf on pf.productfamilyid = pg.productfamilyid\n",
    "                INNER JOIN vsisp42.productcategory pc on pc.productcategoryid = pf.productcategoryid\n",
    "\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"dim_product erfolgreich befüllt.\")\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    populate_dim_product(conn)"
   ],
   "id": "fb9c1d9cef9d7d07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DimProduct erfolgreich befüllt.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T10:04:16.484012Z",
     "start_time": "2025-06-30T10:04:16.377880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def populate_dim_geo(conn):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_geo (\n",
    "                shop_id,\n",
    "                shop_name,\n",
    "                city_id,\n",
    "                city_name,\n",
    "                region_id,\n",
    "                region_name,\n",
    "                country_id,\n",
    "                country_name\n",
    "            )\n",
    "            SELECT\n",
    "                s.ShopID,\n",
    "                s.Name,\n",
    "                c.CityID,\n",
    "                c.Name,\n",
    "                r.RegionID,\n",
    "                r.Name,\n",
    "                co.CountryID,\n",
    "                co.Name\n",
    "            FROM Shop s\n",
    "                INNER JOIN City c ON s.CityID = c.CityID\n",
    "                INNER JOIN Region r ON c.RegionID = r.RegionID\n",
    "                INNER JOIN Country co ON r.CountryID = co.CountryID\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"dim_geo erfolgreich befüllt.\")\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    populate_dim_geo(conn)"
   ],
   "id": "5aa31f0ad398d8df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_geo erfolgreich befüllt.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T12:19:57.525625Z",
     "start_time": "2025-06-30T12:19:56.134728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = load_csv_data()\n",
    "\n",
    "def populate_dim_time(conn, df_sales):\n",
    "\n",
    "    df_sales['date'] = pd.to_datetime(df_sales['date'], errors='coerce')\n",
    "    print(df_sales.head())\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    populate_dim_time(conn, df)"
   ],
   "id": "d57f01cebdfd2072",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/dis-exercise-KLflHRAJ-py3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3811\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/index.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m     \u001B[38;5;28mprint\u001B[39m(df_sales.head())\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m psycopg2.connect(**conn_params) \u001B[38;5;28;01mas\u001B[39;00m conn:\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m     \u001B[43mpopulate_dim_time\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 5\u001B[39m, in \u001B[36mpopulate_dim_time\u001B[39m\u001B[34m(conn, df_sales)\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpopulate_dim_time\u001B[39m(conn, df_sales):\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     df_sales[\u001B[33m'\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m'\u001B[39m] = pd.to_datetime(\u001B[43mdf_sales\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdate\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m, errors=\u001B[33m'\u001B[39m\u001B[33mcoerce\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      6\u001B[39m     \u001B[38;5;28mprint\u001B[39m(df_sales.head())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/dis-exercise-KLflHRAJ-py3.12/lib/python3.12/site-packages/pandas/core/frame.py:4107\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4105\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4106\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4107\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4108\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4109\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Library/Caches/pypoetry/virtualenvs/dis-exercise-KLflHRAJ-py3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3814\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3815\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3816\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3817\u001B[39m     ):\n\u001B[32m   3818\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3819\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3820\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3821\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3822\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3823\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3824\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'date'"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
