{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T13:13:15.024558Z",
     "start_time": "2025-06-30T13:13:15.004859Z"
    }
   },
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "dis_db_password = os.getenv(\"REMOTE_POSTGRES_DIS_PASSWORD\")\n",
    "\n",
    "conn_params = {\n",
    "    'host': 'vsisdb.informatik.uni-hamburg.de',\n",
    "    'dbname': 'dis-2025',\n",
    "    'user': 'vsisp42',\n",
    "    'password': dis_db_password\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:13:16.996375Z",
     "start_time": "2025-06-30T13:13:16.794888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_existing_tables():\n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                SELECT table_name\n",
    "                FROM information_schema.tables\n",
    "                WHERE table_schema = %s\n",
    "                ORDER BY table_name;\n",
    "                \"\"\",\n",
    "                (conn_params[\"user\"],),\n",
    "            )\n",
    "            tables = cur.fetchall()\n",
    "\n",
    "            for table in tables:\n",
    "                print(\"-\", table[0])\n",
    "show_existing_tables()"
   ],
   "id": "c91b3afd2f46f9df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- article\n",
      "- city\n",
      "- country\n",
      "- dim_date\n",
      "- dim_geo\n",
      "- dim_product\n",
      "- fact_sales\n",
      "- productcategory\n",
      "- productfamily\n",
      "- productgroup\n",
      "- region\n",
      "- shop\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:13:20.979498Z",
     "start_time": "2025-06-30T13:13:20.912983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/sales.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read(10000))\n",
    "\n",
    "print(result)"
   ],
   "id": "45f5542699c8ba72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'ISO-8859-1', 'confidence': 0.73, 'language': ''}\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:13:24.671276Z",
     "start_time": "2025-06-30T13:13:24.629662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bad_lines = []\n",
    "with open('resources/sales.csv', encoding='ISO-8859-1') as f:\n",
    "    for i, line in enumerate(f, start=1):\n",
    "        if line.count(';') != 4:  # 4 Semikolons = 5 Spalten\n",
    "            bad_lines.append((i, line.strip()))\n",
    "\n",
    "for i, l in bad_lines:\n",
    "    print(f\"Fehler in Zeile {i}: {l}\")"
   ],
   "id": "d36cfb2d813d6333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler in Zeile 35906: 06.04.2019;12.03.2019;Superstore Dresden;AEG Öko Lavatherm 59850 Sensidry;3;2997,00\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:13:32.077052Z",
     "start_time": "2025-06-30T13:13:32.010485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_csv_data():\n",
    "    return pd.read_csv(\n",
    "        'resources/sales.csv',\n",
    "        encoding='ISO-8859-1',\n",
    "        sep=';',\n",
    "        decimal=',',\n",
    "        on_bad_lines='skip'\n",
    "    )\n",
    "\n",
    "df = load_csv_data()\n",
    "print(df.head())\n"
   ],
   "id": "6f044104fb29fba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date               Shop                           Article  Sold  \\\n",
      "0  01.01.2019  Superstore Berlin  AEG Öko Lavatherm 59850 Sensidry    25   \n",
      "1  01.01.2019  Superstore Berlin     AEG Öko-Lavamat Öko Plus 1400    25   \n",
      "2  01.01.2019  Superstore Berlin              Bauknecht TK Care 6B    13   \n",
      "3  01.01.2019  Superstore Berlin      Bauknecht WA Sensitive 36 DI     2   \n",
      "4  01.01.2019  Superstore Berlin                       BenQ DE350P    31   \n",
      "\n",
      "    Revenue  \n",
      "0  24975.00  \n",
      "1  14975.00  \n",
      "2   3639.74  \n",
      "3    699.80  \n",
      "4   8369.69  \n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:13:34.514318Z",
     "start_time": "2025-06-30T13:13:34.433218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_star_schema_tables(conn):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS dim_product (\n",
    "                product_id SERIAL PRIMARY KEY,\n",
    "                article_id INT,\n",
    "                article_name VARCHAR(255),\n",
    "                product_group_id INT,\n",
    "                product_group_name VARCHAR(255),\n",
    "                product_family_id INT,\n",
    "                product_family_name VARCHAR(255),\n",
    "                product_category_id INT,\n",
    "                product_category_name VARCHAR(255)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS dim_geo (\n",
    "                geo_id SERIAL PRIMARY KEY,\n",
    "                shop_id INT,\n",
    "                shop_name VARCHAR(255),\n",
    "                city_id INT,\n",
    "                city_name VARCHAR(255),\n",
    "                region_id INT,\n",
    "                region_name VARCHAR(255),\n",
    "                country_id INT,\n",
    "                country_name VARCHAR(255)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS dim_date (\n",
    "                date DATE PRIMARY KEY,\n",
    "                day INT,\n",
    "                month INT,\n",
    "                quarter INT,\n",
    "                year INT\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS fact_sales (\n",
    "                sales_id SERIAL PRIMARY KEY,\n",
    "                date Date,\n",
    "                geo_id INT,\n",
    "                product_id INT,\n",
    "                quantity INT,\n",
    "                revenue NUMERIC,\n",
    "\n",
    "                CONSTRAINT fk_date FOREIGN KEY (date) REFERENCES dim_date(date),\n",
    "                CONSTRAINT fk_geo FOREIGN KEY (geo_id) REFERENCES dim_geo(geo_id),\n",
    "                CONSTRAINT fk_product FOREIGN KEY (product_id) REFERENCES dim_product(product_id)\n",
    "            );\n",
    "        \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"Star-Schema-Tabellen erfolgreich erstellt.\")\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    create_star_schema_tables(conn)"
   ],
   "id": "b337d55f28f87295",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star-Schema-Tabellen erfolgreich erstellt.\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:13:39.639390Z",
     "start_time": "2025-06-30T13:13:39.637335Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ba1c020402040656",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:13:41.695890Z",
     "start_time": "2025-06-30T13:13:41.565527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def populate_dim_product(conn):\n",
    "    with conn.cursor() as cur:\n",
    "         cur.execute(\"\"\"\n",
    "            INSERT INTO dim_product (\n",
    "                article_id,\n",
    "                article_name,\n",
    "                product_group_id,\n",
    "                product_group_name,\n",
    "                product_family_id,\n",
    "                product_family_name,\n",
    "                product_category_id,\n",
    "                product_category_name\n",
    "            )\n",
    "            SELECT\n",
    "                a.ArticleID,\n",
    "                a.Name,\n",
    "                pg.ProductGroupID,\n",
    "                pg.Name,\n",
    "                pf.ProductFamilyID,\n",
    "                pf.Name,\n",
    "                pc.ProductCategoryID,\n",
    "                pc.Name\n",
    "            FROM Article a\n",
    "                INNER JOIN ProductGroup pg ON pg.productgroupid = a.productgroupid\n",
    "                INNER JOIN vsisp42.productfamily pf on pf.productfamilyid = pg.productfamilyid\n",
    "                INNER JOIN vsisp42.productcategory pc on pc.productcategoryid = pf.productcategoryid\n",
    "\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"dim_product erfolgreich befüllt.\")\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    populate_dim_product(conn)"
   ],
   "id": "fb9c1d9cef9d7d07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_product erfolgreich befüllt.\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:14:34.264636Z",
     "start_time": "2025-06-30T13:14:34.207216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def populate_dim_geo(conn):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_geo (\n",
    "                shop_id,\n",
    "                shop_name,\n",
    "                city_id,\n",
    "                city_name,\n",
    "                region_id,\n",
    "                region_name,\n",
    "                country_id,\n",
    "                country_name\n",
    "            )\n",
    "            SELECT\n",
    "                s.ShopID,\n",
    "                s.Name,\n",
    "                c.CityID,\n",
    "                c.Name,\n",
    "                r.RegionID,\n",
    "                r.Name,\n",
    "                co.CountryID,\n",
    "                co.Name\n",
    "            FROM Shop s\n",
    "                INNER JOIN City c ON s.CityID = c.CityID\n",
    "                INNER JOIN Region r ON c.RegionID = r.RegionID\n",
    "                INNER JOIN Country co ON r.CountryID = co.CountryID\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"dim_geo erfolgreich befüllt.\")\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    populate_dim_geo(conn)"
   ],
   "id": "5aa31f0ad398d8df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_geo erfolgreich befüllt.\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:14:39.755673Z",
     "start_time": "2025-06-30T13:14:39.677380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform_data(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y', errors='coerce')\n",
    "    num_invalid_dates = df['Date'].isna().sum()\n",
    "    print(f'Entries: {len(df)}\\t number of invaled dates: {num_invalid_dates}')\n",
    "    print(df.head())\n",
    "    # df_sales = df_sales.dropna(subset=['Date'])\n",
    "\n",
    "df = load_csv_data()\n",
    "transform_data(df)"
   ],
   "id": "fc57225c60982ca0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries: 77311\t number of invaled dates: 0\n",
      "        Date               Shop                           Article  Sold  \\\n",
      "0 2019-01-01  Superstore Berlin  AEG Öko Lavatherm 59850 Sensidry    25   \n",
      "1 2019-01-01  Superstore Berlin     AEG Öko-Lavamat Öko Plus 1400    25   \n",
      "2 2019-01-01  Superstore Berlin              Bauknecht TK Care 6B    13   \n",
      "3 2019-01-01  Superstore Berlin      Bauknecht WA Sensitive 36 DI     2   \n",
      "4 2019-01-01  Superstore Berlin                       BenQ DE350P    31   \n",
      "\n",
      "    Revenue  \n",
      "0  24975.00  \n",
      "1  14975.00  \n",
      "2   3639.74  \n",
      "3    699.80  \n",
      "4   8369.69  \n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:14:44.023893Z",
     "start_time": "2025-06-30T13:14:42.514031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def populate_dim_date(conn, df_sales):\n",
    "\n",
    "    min_date = df_sales['Date'].min()\n",
    "    max_date = df_sales['Date'].max()\n",
    "\n",
    "    print(f\"Erzeuge Zeitdimension von {min_date.date()} bis {max_date.date()}\")\n",
    "\n",
    "    date_range = pd.date_range(start=min_date, end=max_date)\n",
    "\n",
    "    df_time = pd.DataFrame({'date': date_range})\n",
    "    df_time['day'] = df_time['date'].dt.day\n",
    "    df_time['month'] = df_time['date'].dt.month\n",
    "    df_time['quarter'] = df_time['date'].dt.quarter\n",
    "    df_time['year'] = df_time['date'].dt.year\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        for _, row in df_time.iterrows():\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO dim_date (date, day, month, quarter, year)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\", (row['date'], row['day'], row['month'], row['quarter'], row['year']))\n",
    "\n",
    "    conn.commit()\n",
    "    print(f\"DimTime befüllt mit {len(df_time)} Tagen.\")\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    populate_dim_date(conn, df)"
   ],
   "id": "d57f01cebdfd2072",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erzeuge Zeitdimension von 2019-01-01 bis 2019-05-31\n",
      " DimTime befüllt mit 151 Tagen.\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-30T13:15:39.816988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def insert_fact_sales(conn, df_sales):\n",
    "    with conn.cursor() as cur:\n",
    "        for _, row in df_sales.iterrows():\n",
    "            cur.execute(\"SELECT date FROM dim_date WHERE date = %s\", (row['Date'],))\n",
    "            time_result = cur.fetchone()\n",
    "            if not time_result:\n",
    "                continue\n",
    "            date = time_result[0]\n",
    "\n",
    "            # Hole geo_id\n",
    "            cur.execute(\"SELECT geo_id FROM dim_geo WHERE shop_name = %s\", (row['Shop'],))\n",
    "            geo_result = cur.fetchone()\n",
    "            if not geo_result:\n",
    "                continue\n",
    "            geo_id = geo_result[0]\n",
    "\n",
    "            # Hole product_id\n",
    "            cur.execute(\"SELECT product_id FROM dim_product WHERE article_name = %s\", (row['Article'],))\n",
    "            product_result = cur.fetchone()\n",
    "            if not product_result:\n",
    "                continue\n",
    "            product_id = product_result[0]\n",
    "\n",
    "            # Insert Fact Record\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO fact_sales (date, geo_id, product_id, quantity, revenue)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\", (date, geo_id, product_id, row['Sold'], row['Revenue']))\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"FactSales erfolgreich befüllt.\")\n",
    "\n",
    "with psycopg2.connect(**conn_params) as conn:\n",
    "    insert_fact_sales(conn, df)\n"
   ],
   "id": "d4189800bc12874d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
